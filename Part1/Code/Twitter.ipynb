{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for Collecting Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jsonpickle\n",
    "import os\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(tweepy.AppAuthHandler(\"jkCRyHMYiZsDakGgPZToA5EIH\", \"401xvck1x9AFr51ConLx8o7UjokWIrcyahgtwc1DWmwVULWISM\"), \n",
    "                 wait_on_rate_limit=True,\n",
    "                 wait_on_rate_limit_notify=True)\n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "    sys.exit(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Tweepy api to get the tweets and used the language filter, Time filter and query terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading max 10000000 tweets\n",
      "Downloaded 98 tweets\n",
      "Downloaded 189 tweets\n",
      "Downloaded 286 tweets\n",
      "Downloaded 375 tweets\n",
      "Downloaded 458 tweets\n",
      "Downloaded 539 tweets\n",
      "Downloaded 637 tweets\n",
      "Downloaded 712 tweets\n",
      "Downloaded 803 tweets\n",
      "Downloaded 892 tweets\n",
      "Downloaded 980 tweets\n",
      "Downloaded 1072 tweets\n",
      "Downloaded 1158 tweets\n",
      "Downloaded 1234 tweets\n",
      "Downloaded 1310 tweets\n",
      "Downloaded 1387 tweets\n",
      "Downloaded 1474 tweets\n",
      "Downloaded 1563 tweets\n",
      "Downloaded 1662 tweets\n",
      "Downloaded 1762 tweets\n",
      "Downloaded 1851 tweets\n",
      "Downloaded 1939 tweets\n",
      "Downloaded 2033 tweets\n",
      "Downloaded 2131 tweets\n",
      "Downloaded 2228 tweets\n",
      "Downloaded 2315 tweets\n",
      "Downloaded 2404 tweets\n",
      "Downloaded 2493 tweets\n",
      "Downloaded 2565 tweets\n",
      "Downloaded 2653 tweets\n",
      "Downloaded 2722 tweets\n",
      "Downloaded 2815 tweets\n",
      "Downloaded 2914 tweets\n",
      "Downloaded 3005 tweets\n",
      "Downloaded 3094 tweets\n",
      "Downloaded 3180 tweets\n",
      "Downloaded 3262 tweets\n",
      "Downloaded 3355 tweets\n",
      "Downloaded 3442 tweets\n",
      "Downloaded 3524 tweets\n",
      "Downloaded 3610 tweets\n",
      "Downloaded 3681 tweets\n",
      "Downloaded 3752 tweets\n",
      "Downloaded 3822 tweets\n",
      "Downloaded 3909 tweets\n",
      "Downloaded 3998 tweets\n",
      "Downloaded 4098 tweets\n",
      "Downloaded 4188 tweets\n",
      "Downloaded 4288 tweets\n",
      "Downloaded 4388 tweets\n",
      "Downloaded 4488 tweets\n",
      "Downloaded 4588 tweets\n",
      "Downloaded 4670 tweets\n",
      "Downloaded 4756 tweets\n",
      "Downloaded 4833 tweets\n",
      "Downloaded 4933 tweets\n",
      "Downloaded 5033 tweets\n",
      "Downloaded 5133 tweets\n",
      "Downloaded 5233 tweets\n",
      "Downloaded 5313 tweets\n",
      "Downloaded 5413 tweets\n",
      "Downloaded 5502 tweets\n",
      "Downloaded 5590 tweets\n",
      "Downloaded 5671 tweets\n",
      "Downloaded 5737 tweets\n",
      "Downloaded 5822 tweets\n",
      "Downloaded 5902 tweets\n",
      "Downloaded 5991 tweets\n",
      "Downloaded 6091 tweets\n",
      "Downloaded 6179 tweets\n",
      "Downloaded 6276 tweets\n",
      "Downloaded 6376 tweets\n",
      "Downloaded 6452 tweets\n",
      "Downloaded 6533 tweets\n",
      "Downloaded 6620 tweets\n",
      "Downloaded 6703 tweets\n",
      "Downloaded 6782 tweets\n",
      "Downloaded 6880 tweets\n",
      "Downloaded 6964 tweets\n",
      "Downloaded 7033 tweets\n",
      "Downloaded 7132 tweets\n",
      "Downloaded 7209 tweets\n",
      "Downloaded 7281 tweets\n",
      "Downloaded 7359 tweets\n",
      "Downloaded 7448 tweets\n",
      "Downloaded 7531 tweets\n",
      "Downloaded 7631 tweets\n",
      "Downloaded 7722 tweets\n",
      "Downloaded 7806 tweets\n",
      "Downloaded 7893 tweets\n",
      "Downloaded 7989 tweets\n",
      "Downloaded 8085 tweets\n",
      "Downloaded 8171 tweets\n",
      "Downloaded 8261 tweets\n",
      "Downloaded 8350 tweets\n",
      "Downloaded 8436 tweets\n",
      "Downloaded 8499 tweets\n",
      "Downloaded 8575 tweets\n",
      "Downloaded 8675 tweets\n",
      "Downloaded 8775 tweets\n",
      "Downloaded 8866 tweets\n",
      "Downloaded 8964 tweets\n",
      "Downloaded 9064 tweets\n",
      "Downloaded 9145 tweets\n",
      "Downloaded 9228 tweets\n",
      "Downloaded 9318 tweets\n",
      "Downloaded 9410 tweets\n",
      "Downloaded 9499 tweets\n",
      "Downloaded 9599 tweets\n",
      "Downloaded 9685 tweets\n",
      "Downloaded 9759 tweets\n",
      "Downloaded 9818 tweets\n",
      "Downloaded 9907 tweets\n",
      "Downloaded 9998 tweets\n",
      "Downloaded 10098 tweets\n",
      "Downloaded 10195 tweets\n",
      "Downloaded 10289 tweets\n",
      "Downloaded 10374 tweets\n",
      "Downloaded 10458 tweets\n",
      "Downloaded 10548 tweets\n",
      "Downloaded 10635 tweets\n",
      "Downloaded 10725 tweets\n",
      "Downloaded 10811 tweets\n",
      "Downloaded 10906 tweets\n",
      "Downloaded 11003 tweets\n",
      "Downloaded 11091 tweets\n",
      "Downloaded 11168 tweets\n",
      "Downloaded 11246 tweets\n",
      "Downloaded 11326 tweets\n",
      "Downloaded 11414 tweets\n",
      "Downloaded 11508 tweets\n",
      "Downloaded 11608 tweets\n",
      "Downloaded 11708 tweets\n",
      "Downloaded 11794 tweets\n",
      "Downloaded 11887 tweets\n",
      "Downloaded 11987 tweets\n",
      "Downloaded 12078 tweets\n",
      "Downloaded 12177 tweets\n",
      "Downloaded 12268 tweets\n",
      "Downloaded 12363 tweets\n",
      "Downloaded 12454 tweets\n",
      "Downloaded 12547 tweets\n",
      "Downloaded 12647 tweets\n",
      "Downloaded 12735 tweets\n",
      "Downloaded 12824 tweets\n",
      "Downloaded 12907 tweets\n",
      "Downloaded 12976 tweets\n",
      "Downloaded 13061 tweets\n",
      "Downloaded 13158 tweets\n",
      "Downloaded 13249 tweets\n",
      "Downloaded 13339 tweets\n",
      "Downloaded 13434 tweets\n",
      "Downloaded 13534 tweets\n",
      "Downloaded 13634 tweets\n",
      "Downloaded 13713 tweets\n",
      "Downloaded 13812 tweets\n",
      "Downloaded 13838 tweets\n",
      "No more tweets found\n",
      "Downloaded 13838 tweets, Saved to tweets_soccer.txt\n"
     ]
    }
   ],
   "source": [
    "searchQuery = '#soccer, '  # this is what we're searching for\n",
    "maxTweets = 10000000 # Some arbitrary large number\n",
    "tweetsPerQry = 100  # this is the max the API permits\n",
    "fName = 'tweets_soccer.txt' # We'll store the tweets in a text file.\n",
    "sinceId = 20190411\n",
    "lang = 'en'  #language filtering\n",
    "max_id = -100\n",
    "tweetCount = 0\n",
    "print(\"Downloading max {0} tweets\".format(maxTweets))\n",
    "with open(fName, 'w',encoding='utf8') as f:\n",
    "    while tweetCount < maxTweets:\n",
    "        try:\n",
    "            if (max_id <= 0):\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry, lang='en')\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            since_id=sinceId, lang='en')\n",
    "            else:\n",
    "                if (not sinceId):\n",
    "                    new_tweets = api.search(q=searchQuery, lang='en', count=tweetsPerQry,\n",
    "                                            max_id=str(max_id - 1))\n",
    "                else:\n",
    "                    new_tweets = api.search(q=searchQuery, lang='en', count=tweetsPerQry,\n",
    "                                            max_id=str(max_id - 1),\n",
    "                                            since_id=sinceId)\n",
    "            if not new_tweets:\n",
    "                print(\"No more tweets found\")\n",
    "                break\n",
    "            for tweet in new_tweets:\n",
    "                f.write(tweet._json[\"text\"].replace(\"RT\",\"\")+\"\\n\")\n",
    "            tweetCount += len(new_tweets)\n",
    "            print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "            max_id = new_tweets[-1].id\n",
    "        except tweepy.TweepError as e:\n",
    "            # Just exit if any error\n",
    "            print(\"some error : \" + str(e))\n",
    "            break\n",
    "\n",
    "print (\"Downloaded {0} tweets, Saved to {1}\".format(tweetCount, fName))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refernce: https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
